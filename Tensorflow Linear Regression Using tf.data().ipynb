{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_FILE = 'life_birth.txt'\n",
    "\n",
    "# Step 1: read in the data\n",
    "# Read the data into a dataset.\n",
    "data, n_samples = utils.read_birth_life_data(DATA_FILE)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data[:,0], data[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 2: create Dataset and iterator\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data[:,1], data[:,2]))\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "X, Y = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 3: create weight and bias, initialized to 0\n",
    "w = tf.get_variable('weights', initializer=tf.constant(0.0))\n",
    "b = tf.get_variable('bias', initializer=tf.constant(0.0))\n",
    "\n",
    "# Step 4: build model to predict Y\n",
    "Y_predicted = X * w + b\n",
    "\n",
    "# Step 5: use the square error as the loss function\n",
    "loss = tf.square(Y - Y_predicted, name='loss')\n",
    "# loss = utils.huber_loss(Y, Y_predicted)\n",
    "\n",
    "# Step 6: using gradient descent with learning rate of 0.001 to minimize loss\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "with tf.Session() as sess:\n",
    "    # Step 7: initialize the necessary variables, in this case, w and b\n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "    writer = tf.summary.FileWriter('./graphs/linear_reg', sess.graph)\n",
    "    \n",
    "    # Step 8: train the model for 100 epochs\n",
    "    for i in range(100):\n",
    "        sess.run(iterator.initializer) # initialize the iterator\n",
    "        total_loss = 0\n",
    "        try:\n",
    "            while True:\n",
    "                _, l = sess.run([optimizer, loss]) \n",
    "                total_loss += l\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "            \n",
    "        print('Epoch {0}: {1}'.format(i, total_loss/n_samples))\n",
    "\n",
    "    # close the writer when you're done using it\n",
    "    writer.close() \n",
    "    \n",
    "    # Step 9: output the values of w and b\n",
    "    w_out, b_out = sess.run([w, b]) \n",
    "    print('w: %f, b: %f' %(w_out, b_out))\n",
    "print('Took: %f seconds' %(time.time() - start))\n",
    "\n",
    "# plot the results\n",
    "plt.plot(data[:,0], data[:,1], 'bo', label='Real data')\n",
    "plt.plot(data[:,0], data[:,0] * w_out + b_out, 'r', label='Predicted data with squared error')\n",
    "# plt.plot(data[:,0], data[:,0] * (-5.883589) + 85.124306, 'g', label='Predicted data with Huber loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
